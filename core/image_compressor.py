#!/usr/bin/env python3
"""
å›¾ç‰‡å‹ç¼©æ¨¡å— - è´Ÿè´£å°†æ¼«ç”»æ–‡ä»¶ä¸­çš„å›¾ç‰‡è½¬æ¢ä¸ºWebPæ ¼å¼
"""

import os
import tempfile
import zipfile
import cv2
import shutil
from pathlib import Path
from typing import List, Dict, Any, Callable, Optional
from datetime import datetime
import threading
import time

from utils import manga_logger as log


class ImageCompressor:
    """å›¾ç‰‡å‹ç¼©å™¨"""
    
    def __init__(self):
        self.is_compressing = False
        self.current_task = None
        self.progress_callback = None
        self.cancel_flag = threading.Event()
        
    def compress_manga_file(
        self,
        file_path: str,
        webp_quality: int = 100,
        preserve_original_names: bool = False,
        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None
    ) -> Dict[str, Any]:
        """
        å‹ç¼©æ¼«ç”»æ–‡ä»¶ï¼ˆWebç‰ˆæœ¬ä»…æ”¯æŒä¸‹è½½æ¨¡å¼ï¼‰

        Args:
            file_path: æ¼«ç”»æ–‡ä»¶è·¯å¾„
            webp_quality: WebPè´¨é‡ (0-100)
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            å‹ç¼©ç»“æœå­—å…¸
        """
        try:
            log.info(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] å¼€å§‹å‹ç¼©ä»»åŠ¡:")
            log.info(f"  - æ–‡ä»¶è·¯å¾„: {file_path}")
            log.info(f"  - WebPè´¨é‡: {webp_quality}")
            log.info(f"  - å‹ç¼©æ¨¡å¼: download (Webç‰ˆæœ¬å›ºå®š)")
            log.info(f"  - è¿›åº¦å›è°ƒ: {'æœ‰' if progress_callback else 'æ— '}")

            self.is_compressing = True
            self.progress_callback = progress_callback
            self.cancel_flag.clear()

            # éªŒè¯å‚æ•°
            log.info(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] éªŒè¯å‚æ•°...")
            if not file_path:
                log.error(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] æ–‡ä»¶è·¯å¾„ä¸ºç©º")
                raise ValueError("æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")

            if not os.path.exists(file_path):
                log.error(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            file_size = os.path.getsize(file_path)
            log.info(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] æ–‡ä»¶å¤§å°: {file_size:,} bytes")

            if not file_path.lower().endswith(('.zip', '.cbz', '.cbr')):
                log.error(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                raise ValueError("åªæ”¯æŒZIPã€CBZã€CBRæ ¼å¼çš„å‹ç¼©æ–‡ä»¶")

            webp_quality = max(0, min(100, webp_quality))
            log.info(f"ğŸ”§ [å‹ç¼©å™¨è°ƒè¯•] è°ƒæ•´åçš„WebPè´¨é‡: {webp_quality}")

            log.info(f"å¼€å§‹å‹ç¼©æ¼«ç”»æ–‡ä»¶: {file_path}")
            log.info(f"WebPè´¨é‡: {webp_quality}, æ¨¡å¼: download (Webç‰ˆæœ¬å›ºå®š)")
            
            # æŠ¥å‘Šå¼€å§‹çŠ¶æ€
            self._report_progress({
                "status": "starting",
                "message": "å¼€å§‹è§£å‹æ–‡ä»¶...",
                "progress": 0,
                "total_steps": 4,
                "current_step": 1
            })
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                extract_dir = os.path.join(temp_dir, "extracted")
                output_dir = os.path.join(temp_dir, "compressed")
                os.makedirs(extract_dir, exist_ok=True)
                os.makedirs(output_dir, exist_ok=True)
                
                # æ­¥éª¤1: è§£å‹æ–‡ä»¶
                image_files = self._extract_images(file_path, extract_dir)
                if self.cancel_flag.is_set():
                    return {"success": False, "message": "æ“ä½œå·²å–æ¶ˆ"}

                # æ­¥éª¤1.5: å‹ç¼©é¢„æ£€æµ‹
                should_compress = self._test_compression_effectiveness(image_files[0], webp_quality)
                if not should_compress:
                    log.info("ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] å‹ç¼©æ•ˆæœä¸ç†æƒ³ï¼Œè·³è¿‡å‹ç¼©")
                    return {
                        "success": False,
                        "message": "å‹ç¼©åŒ…å†…å›¾ç‰‡å·²ç»é«˜åº¦å‹ç¼©ï¼Œæ— éœ€å†æ¬¡å‹ç¼©",
                        "skip_reason": "compression_not_effective"
                    }

                # æ­¥éª¤2: è½¬æ¢å›¾ç‰‡
                converted_files = self._convert_images(image_files, output_dir, webp_quality, preserve_original_names)
                if self.cancel_flag.is_set():
                    return {"success": False, "message": "æ“ä½œå·²å–æ¶ˆ"}
                
                # æ­¥éª¤3: åˆ›å»ºè¾“å‡ºæ–‡ä»¶ï¼ˆWebç‰ˆæœ¬ä»…æ”¯æŒä¸‹è½½æ¨¡å¼ï¼‰
                result = self._create_output(file_path, converted_files)
                if self.cancel_flag.is_set():
                    return {"success": False, "message": "æ“ä½œå·²å–æ¶ˆ"}
                
                # æ­¥éª¤4: å®Œæˆ
                self._report_progress({
                    "status": "completed",
                    "message": "å‹ç¼©å®Œæˆ",
                    "progress": 100,
                    "total_steps": 4,
                    "current_step": 4
                })
                
                log.info(f"å‹ç¼©å®Œæˆ: {file_path}")
                return result
                
        except Exception as e:
            log.error(f"å‹ç¼©å¤±è´¥: {e}")
            self._report_progress({
                "status": "error",
                "message": f"å‹ç¼©å¤±è´¥: {str(e)}",
                "progress": 0
            })
            return {"success": False, "message": str(e)}
        finally:
            self.is_compressing = False
            self.current_task = None
            self.progress_callback = None
    
    def _extract_images(self, file_path: str, extract_dir: str) -> List[str]:
        """è§£å‹å¹¶è·å–å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨"""
        self._report_progress({
            "status": "extracting",
            "message": "æ­£åœ¨è§£å‹æ–‡ä»¶...",
            "progress": 10,
            "total_steps": 4,
            "current_step": 1
        })
        
        try:
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
        except Exception as e:
            raise Exception(f"è§£å‹æ–‡ä»¶å¤±è´¥: {e}")
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif'}
        image_files = []
        
        for root, _, files in os.walk(extract_dir):
            for file in files:
                if Path(file).suffix.lower() in image_extensions:
                    image_files.append(os.path.join(root, file))
        
        if not image_files:
            raise Exception("å‹ç¼©åŒ…ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        
        # æŒ‰æ–‡ä»¶åæ’åº
        image_files.sort()
        
        log.info(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        
        self._report_progress({
            "status": "extracted",
            "message": f"è§£å‹å®Œæˆï¼Œæ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡",
            "progress": 25,
            "total_steps": 4,
            "current_step": 1,
            "total_images": len(image_files)
        })
        
        return image_files

    def _test_compression_effectiveness(self, first_image_path: str, webp_quality: int) -> bool:
        """
        æµ‹è¯•ç¬¬ä¸€å¼ å›¾ç‰‡çš„å‹ç¼©æ•ˆæœ

        Args:
            first_image_path: ç¬¬ä¸€å¼ å›¾ç‰‡çš„è·¯å¾„
            webp_quality: WebPè´¨é‡è®¾ç½®

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥è¿›è¡Œå‹ç¼©ï¼ŒFalseè¡¨ç¤ºè·³è¿‡å‹ç¼©
        """
        try:
            log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] å¼€å§‹æµ‹è¯•ç¬¬ä¸€å¼ å›¾ç‰‡çš„å‹ç¼©æ•ˆæœ...")
            log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] æµ‹è¯•å›¾ç‰‡: {os.path.basename(first_image_path)}")

            # æŠ¥å‘Šé¢„æ£€æµ‹è¿›åº¦
            self._report_progress({
                "status": "testing",
                "message": "æ­£åœ¨æµ‹è¯•å‹ç¼©æ•ˆæœ...",
                "progress": 20,
                "total_steps": 4,
                "current_step": 1
            })

            # è·å–åŸå§‹æ–‡ä»¶å¤§å°
            original_size = os.path.getsize(first_image_path)
            log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] åŸå§‹æ–‡ä»¶å¤§å°: {original_size:,} bytes")

            # è¯»å–å›¾ç‰‡
            img = cv2.imread(first_image_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                log.warning(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] æ— æ³•è¯»å–æµ‹è¯•å›¾ç‰‡ï¼Œè·³è¿‡é¢„æ£€æµ‹")
                return True  # æ— æ³•è¯»å–æ—¶é»˜è®¤è¿›è¡Œå‹ç¼©

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è¿›è¡Œå‹ç¼©æµ‹è¯•
            with tempfile.NamedTemporaryFile(suffix='.webp', delete=False) as temp_file:
                temp_webp_path = temp_file.name

            try:
                # è®¾ç½®WebPå‹ç¼©å‚æ•°
                if webp_quality == 100:
                    # æ— æŸå‹ç¼© - ä½¿ç”¨WebPæ— æŸæ¨¡å¼
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, 101]  # 101è¡¨ç¤ºæ— æŸæ¨¡å¼
                else:
                    # æœ‰æŸå‹ç¼©
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, webp_quality]

                # å‹ç¼©ä¸ºWebP
                success = cv2.imwrite(temp_webp_path, img, encode_params)
                if not success:
                    log.warning(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] WebPå‹ç¼©å¤±è´¥ï¼Œè·³è¿‡é¢„æ£€æµ‹")
                    return True  # å‹ç¼©å¤±è´¥æ—¶é»˜è®¤è¿›è¡Œå‹ç¼©

                # è·å–å‹ç¼©åæ–‡ä»¶å¤§å°
                compressed_size = os.path.getsize(temp_webp_path)
                log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] å‹ç¼©åæ–‡ä»¶å¤§å°: {compressed_size:,} bytes")

                # è®¡ç®—å‹ç¼©ç‡
                if original_size > 0:
                    compression_ratio = (original_size - compressed_size) / original_size
                    compression_percentage = compression_ratio * 100

                    log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] å‹ç¼©ç‡: {compression_percentage:.1f}%")
                    log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] æ–‡ä»¶å¤§å°å˜åŒ–: {original_size:,} -> {compressed_size:,} bytes")

                    # åˆ¤æ–­æ˜¯å¦å€¼å¾—å‹ç¼©ï¼ˆå‹ç¼©åæ–‡ä»¶å¤§å°å‡å°‘25%ä»¥ä¸Šæ‰è¿›è¡Œå‹ç¼©ï¼‰
                    threshold = 0.25  # 25%é˜ˆå€¼
                    should_compress = compression_ratio >= threshold

                    if should_compress:
                        log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] âœ… å‹ç¼©æ•ˆæœè‰¯å¥½ ({compression_percentage:.1f}% >= 25%)ï¼Œç»§ç»­å‹ç¼©")
                    else:
                        log.info(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] âŒ å‹ç¼©æ•ˆæœä¸ç†æƒ³ ({compression_percentage:.1f}% < 25%)ï¼Œè·³è¿‡å‹ç¼©")

                    return should_compress
                else:
                    log.warning(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] åŸå§‹æ–‡ä»¶å¤§å°ä¸º0ï¼Œè·³è¿‡é¢„æ£€æµ‹")
                    return True

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(temp_webp_path):
                        os.unlink(temp_webp_path)
                except Exception as e:
                    log.warning(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        except Exception as e:
            log.error(f"ğŸ”§ [å‹ç¼©é¢„æ£€æµ‹] é¢„æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤è¿›è¡Œå‹ç¼©

    def _convert_images(self, image_files: List[str], output_dir: str, webp_quality: int, preserve_original_names: bool = False) -> List[str]:
        """è½¬æ¢å›¾ç‰‡ä¸ºWebPæ ¼å¼ï¼ˆæ”¯æŒå¤šçº¿ç¨‹ï¼‰"""
        self._report_progress({
            "status": "converting",
            "message": "å¼€å§‹è½¬æ¢å›¾ç‰‡æ ¼å¼...",
            "progress": 30,
            "total_steps": 4,
            "current_step": 2,
            "converted_images": 0,
            "total_images": len(image_files)
        })

        # æ ¹æ®å›¾ç‰‡æ•°é‡å’ŒCPUæ ¸å¿ƒæ•°å†³å®šæ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹
        import multiprocessing
        import threading
        from concurrent.futures import ThreadPoolExecutor, as_completed

        cpu_count = multiprocessing.cpu_count()
        total_images = len(image_files)

        # å¦‚æœå›¾ç‰‡æ•°é‡å°‘äº10å¼ æˆ–CPUæ ¸å¿ƒæ•°å°‘äº2ï¼Œä½¿ç”¨å•çº¿ç¨‹
        if total_images < 10 or cpu_count < 2:
            return self._convert_images_single_thread(image_files, output_dir, webp_quality, preserve_original_names)

        # ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†
        max_workers = min(cpu_count, 16)  # æœ€å¤š8ä¸ªçº¿ç¨‹
        log.info(f"ä½¿ç”¨å¤šçº¿ç¨‹å‹ç¼©: {max_workers} ä¸ªçº¿ç¨‹å¤„ç† {total_images} å¼ å›¾ç‰‡")

        converted_files = []
        converted_files_lock = threading.Lock()
        progress_lock = threading.Lock()
        completed_count = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹

        def convert_single_image(args):
            """è½¬æ¢å•å¼ å›¾ç‰‡çš„å·¥ä½œå‡½æ•°"""
            i, img_path = args

            if self.cancel_flag.is_set():
                return None

            try:
                # è¯»å–å›¾ç‰‡ï¼Œå¿½ç•¥é¢œè‰²é…ç½®æ–‡ä»¶è­¦å‘Š
                import warnings
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=UserWarning, message=".*iCCP.*")
                    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

                if img is None:
                    log.warning(f"æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
                    return None

                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼Œç¡®ä¿å”¯ä¸€æ€§
                if preserve_original_names:
                    # ä¿ç•™åŸå§‹æ–‡ä»¶åï¼Œåªæ”¹å˜æ‰©å±•å
                    original_name = Path(img_path).stem
                    output_filename = f"{original_name}.webp"

                    # æ£€æŸ¥æ–‡ä»¶åå†²çªï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åºå·
                    counter = 1
                    base_output_path = os.path.join(output_dir, output_filename)
                    output_path = base_output_path

                    while os.path.exists(output_path):
                        name_without_ext = Path(output_filename).stem
                        output_filename = f"{name_without_ext}_{counter}.webp"
                        output_path = os.path.join(output_dir, output_filename)
                        counter += 1

                        # é˜²æ­¢æ— é™å¾ªç¯
                        if counter > 1000:
                            log.error(f"æ–‡ä»¶åå†²çªè¿‡å¤šï¼Œè·³è¿‡: {original_name}")
                            return None
                else:
                    # ä½¿ç”¨åºåˆ—å‘½å
                    output_filename = f"page_{i+1:03d}.webp"
                    output_path = os.path.join(output_dir, output_filename)

                # è®¾ç½®WebPå‹ç¼©å‚æ•°
                if webp_quality == 100:
                    # æ— æŸå‹ç¼© - ä½¿ç”¨WebPæ— æŸæ¨¡å¼
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, 101]  # 101è¡¨ç¤ºæ— æŸæ¨¡å¼
                else:
                    # æœ‰æŸå‹ç¼©
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, webp_quality]

                # ä¿å­˜ä¸ºWebPæ ¼å¼ï¼Œå¿½ç•¥é¢œè‰²é…ç½®æ–‡ä»¶è­¦å‘Š
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=UserWarning, message=".*iCCP.*")
                    success = cv2.imwrite(output_path, img, encode_params)

                if success:
                    log.debug(f"è½¬æ¢å®Œæˆ: {os.path.basename(img_path)} -> {output_filename}")
                    return output_path
                else:
                    log.warning(f"è½¬æ¢å¤±è´¥: {img_path}")
                    return None

            except Exception as e:
                log.error(f"å¤„ç†å›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {e}")
                return None

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œè½¬æ¢
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(convert_single_image, (i, img_path)): i
                for i, img_path in enumerate(image_files)
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                if self.cancel_flag.is_set():
                    break

                result = future.result()
                if result:
                    with converted_files_lock:
                        converted_files.append(result)

                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    completed_count[0] += 1
                    progress = 30 + completed_count[0] / total_images * 40  # 30-70%
                    self._report_progress({
                        "status": "converting",
                        "message": f"æ­£åœ¨è½¬æ¢å›¾ç‰‡ {completed_count[0]}/{total_images} (å¤šçº¿ç¨‹)",
                        "progress": int(progress),
                        "total_steps": 4,
                        "current_step": 2,
                        "converted_images": completed_count[0],
                        "total_images": total_images
                    })

        if not converted_files:
            raise Exception("æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•å›¾ç‰‡")

        # æŒ‰åŸå§‹é¡ºåºæ’åºï¼ˆå¦‚æœä½¿ç”¨åºåˆ—å‘½åï¼‰
        if not preserve_original_names:
            converted_files.sort()

        log.info(f"å¤šçº¿ç¨‹è½¬æ¢å®Œæˆ: {len(converted_files)} ä¸ªå›¾ç‰‡")

        self._report_progress({
            "status": "converted",
            "message": f"å›¾ç‰‡è½¬æ¢å®Œæˆï¼Œå…± {len(converted_files)} ä¸ª",
            "progress": 70,
            "total_steps": 4,
            "current_step": 2,
            "converted_images": len(converted_files),
            "total_images": total_images
        })

        return converted_files

    def _convert_images_single_thread(self, image_files: List[str], output_dir: str, webp_quality: int, preserve_original_names: bool = False) -> List[str]:
        """å•çº¿ç¨‹è½¬æ¢å›¾ç‰‡ï¼ˆåŸå§‹å®ç°ï¼‰"""
        converted_files = []

        for i, img_path in enumerate(image_files):
            if self.cancel_flag.is_set():
                break

            try:
                # è¯»å–å›¾ç‰‡
                img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
                if img is None:
                    log.warning(f"æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
                    continue

                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                if preserve_original_names:
                    # ä¿ç•™åŸå§‹æ–‡ä»¶åï¼Œåªæ”¹å˜æ‰©å±•å
                    original_name = Path(img_path).stem
                    output_filename = f"{original_name}.webp"
                else:
                    # ä½¿ç”¨åºåˆ—å‘½å
                    output_filename = f"page_{i+1:03d}.webp"
                output_path = os.path.join(output_dir, output_filename)

                # è®¾ç½®WebPå‹ç¼©å‚æ•°
                if webp_quality == 100:
                    # æ— æŸå‹ç¼© - ä½¿ç”¨WebPæ— æŸæ¨¡å¼
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, 101]  # 101è¡¨ç¤ºæ— æŸæ¨¡å¼
                else:
                    # æœ‰æŸå‹ç¼©
                    encode_params = [cv2.IMWRITE_WEBP_QUALITY, webp_quality]

                # ä¿å­˜ä¸ºWebPæ ¼å¼
                success = cv2.imwrite(output_path, img, encode_params)
                if success:
                    converted_files.append(output_path)
                    log.debug(f"è½¬æ¢å®Œæˆ: {os.path.basename(img_path)} -> {output_filename}")
                else:
                    log.warning(f"è½¬æ¢å¤±è´¥: {img_path}")

                # æŠ¥å‘Šè¿›åº¦
                progress = 30 + (i + 1) / len(image_files) * 40  # 30-70%
                self._report_progress({
                    "status": "converting",
                    "message": f"æ­£åœ¨è½¬æ¢å›¾ç‰‡ {i+1}/{len(image_files)}",
                    "progress": int(progress),
                    "total_steps": 4,
                    "current_step": 2,
                    "converted_images": i + 1,
                    "total_images": len(image_files)
                })

            except Exception as e:
                log.error(f"å¤„ç†å›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {e}")
                continue

        return converted_files
    
    def _create_output(self, original_file_path: str, converted_files: List[str]) -> Dict[str, Any]:
        """åˆ›å»ºè¾“å‡ºæ–‡ä»¶ï¼ˆWebç‰ˆæœ¬ä»…æ”¯æŒä¸‹è½½æ¨¡å¼ï¼‰"""
        self._report_progress({
            "status": "packaging",
            "message": "æ­£åœ¨æ‰“åŒ…æ–‡ä»¶...",
            "progress": 75,
            "total_steps": 4,
            "current_step": 3
        })
        
        # Webç‰ˆæœ¬åªæ”¯æŒä¸‹è½½æ¨¡å¼ï¼Œä¸æ”¯æŒæ–‡ä»¶æ›¿æ¢
        # åˆ›å»ºä¸´æ—¶ZIPæ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            with zipfile.ZipFile(temp_zip.name, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in converted_files:
                    arcname = os.path.basename(file_path)
                    zipf.write(file_path, arcname)

            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶å
            original_name = Path(original_file_path).stem
            safe_name = "".join(c for c in original_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
            download_name = f"{safe_name}_compressed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"

            self._report_progress({
                "status": "packaged",
                "message": "æ–‡ä»¶æ‰“åŒ…å®Œæˆï¼Œå‡†å¤‡ä¸‹è½½",
                "progress": 95,
                "total_steps": 4,
                "current_step": 3
            })

            return {
                "success": True,
                "message": "æ— æŸå‹ç¼©å®Œæˆ",
                "mode": "download",
                "converted_files": len(converted_files),
                "temp_file": temp_zip.name,
                "download_name": download_name
            }
    
    def _report_progress(self, progress_data: Dict[str, Any]):
        """æŠ¥å‘Šè¿›åº¦"""
        if self.progress_callback:
            try:
                self.progress_callback(progress_data)
            except Exception as e:
                log.error(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
    
    def cancel_compression(self):
        """å–æ¶ˆå‹ç¼©æ“ä½œ"""
        log.info("æ”¶åˆ°å–æ¶ˆå‹ç¼©è¯·æ±‚")
        self.cancel_flag.set()
    
    def get_compression_status(self) -> Dict[str, Any]:
        """è·å–å‹ç¼©çŠ¶æ€"""
        return {
            "is_compressing": self.is_compressing,
            "current_task": self.current_task
        }


# å…¨å±€å‹ç¼©å™¨å®ä¾‹
_compressor_instance = None

def get_image_compressor() -> ImageCompressor:
    """è·å–å›¾ç‰‡å‹ç¼©å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _compressor_instance
    if _compressor_instance is None:
        _compressor_instance = ImageCompressor()
    return _compressor_instance
